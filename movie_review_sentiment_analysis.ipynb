{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movie_review_sentiment_analysis2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Bsu_XD9UPoJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "e74e0291-1977-4846-b7be-909aa395f2e9"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EfLk4aDHQNsS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "01117091-ccfd-4c1e-ee30-7a876a53164f"
      },
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/My Drive/sentiment_analysis_kaggle\"\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/sentiment_analysis_kaggle\n",
            "glove.6B.100d.txt\t\t\tsub1.csv\n",
            "model1_weights.h5\t\t\tsub3.csv\n",
            "model3_weights.h5\t\t\tsub4.csv\n",
            "model4_weights.h5\t\t\tsub5.csv\n",
            "model5_weights.h5\t\t\tsub_shnn.csv\n",
            "movie_review_sentiment_analysis1.ipynb\tsub_xgb.csv\n",
            "movie_review_sentiment_analysis2.ipynb\ttest.tsv\n",
            "sampleSubmission.csv\t\t\ttrain.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y3UUEaLqQRkx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4cffa4f2-9d89-4650-a4a3-0e0c8ff7b018"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import nltk\n",
        "import os\n",
        "import gc\n",
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Embedding,LSTM,Conv1D,GlobalMaxPooling1D,Flatten,MaxPooling1D,GRU,SpatialDropout1D,Bidirectional\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#pd.set_option('display.max_colwidth',100)\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ND8pBxKYQVPt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df=pd.read_csv('train.tsv',sep='\\t')\n",
        "test_df=pd.read_csv('test.tsv',sep='\\t')\n",
        "sub=pd.read_csv('sampleSubmission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bdyi-sp6QX-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "ac76b95f-85b7-4035-a16f-72bdb31d19a1"
      },
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist\n",
        "from nltk.stem import SnowballStemmer,WordNetLemmatizer\n",
        "stemmer=SnowballStemmer('english')\n",
        "lemma=WordNetLemmatizer()\n",
        "from string import punctuation\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "4_PjgcshQo8S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_review(review_col):\n",
        "    review_corpus=[]\n",
        "    for i in range(0,len(review_col)):\n",
        "        review=str(review_col[i])\n",
        "        review=re.sub('[^a-zA-Z]',' ',review)\n",
        "        #review=[stemmer.stem(w) for w in word_tokenize(str(review).lower())]\n",
        "        review=[lemma.lemmatize(w) for w in word_tokenize(str(review).lower())]\n",
        "        review=' '.join(review)\n",
        "        review_corpus.append(review)\n",
        "    return review_corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bEbjap2iQrzw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df['clean_review']=clean_review(train_df.Phrase.values)\n",
        "test_df['clean_review']=clean_review(test_df.Phrase.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eD0sSbDmQyHy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b3601226-cfab-403f-d7f7-6e4634797bb6"
      },
      "cell_type": "code",
      "source": [
        "train_text=train_df.clean_review.values\n",
        "test_text=test_df.clean_review.values\n",
        "target=train_df.Sentiment.values\n",
        "y=to_categorical(target)\n",
        "print(train_text.shape,test_text.shape,y.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(156060,) (66292,) (156060, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kByHb2BFQ65B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a473c0b2-f386-4d9a-967a-aba2839e6ae4"
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "c = Counter( target )\n",
        "print( c.items() )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_items([(1, 27273), (2, 79582), (3, 32927), (4, 9206), (0, 7072)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dbKULWEhRCrC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3ada1e1a-519c-4479-e709-54d432f62f6b"
      },
      "cell_type": "code",
      "source": [
        "X_train_text,X_val_text,y_train,y_val=train_test_split(train_text,y,test_size=0.3,random_state=123)\n",
        "\n",
        "print(X_train_text.shape,X_val_text.shape)\n",
        "print(y_train.shape,y_val.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(109242,) (46818,)\n",
            "(109242, 5) (46818, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xp5RGUtXRgfy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "985a6127-5470-49ce-9a5f-5a1b6cd9d70f"
      },
      "cell_type": "code",
      "source": [
        "all_words=' '.join(X_train_text)\n",
        "all_words=word_tokenize(all_words)\n",
        "dist=FreqDist(all_words)\n",
        "num_unique_word=len(dist)\n",
        "num_unique_word"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "s8ZahVeMRlUS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e3bf863a-65fc-4a15-ea3d-2295fa14a101"
      },
      "cell_type": "code",
      "source": [
        "r_len=[]\n",
        "for text in X_train_text:\n",
        "    word=word_tokenize(text)\n",
        "    l=len(word)\n",
        "    r_len.append(l)\n",
        "    \n",
        "MAX_REVIEW_LEN=np.max(r_len)\n",
        "MAX_REVIEW_LEN"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "KHdf5JPiRrU5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a19c5579-ff1f-4ae7-f696-1104aecf9b6c"
      },
      "cell_type": "code",
      "source": [
        "max_features = num_unique_word\n",
        "max_words = MAX_REVIEW_LEN\n",
        "batch_size = 256\n",
        "epochs = 5\n",
        "num_classes=5\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(X_train_text))\n",
        "X_train = tokenizer.texts_to_sequences(X_train_text)\n",
        "X_val = tokenizer.texts_to_sequences(X_val_text)\n",
        "X_test = tokenizer.texts_to_sequences(test_text)\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "print(X_train.shape,X_val.shape,X_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(109242, 48) (46818, 48) (66292, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tvP3lG7v_SzM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Of6ffextSHqI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "LSTM Model"
      ]
    },
    {
      "metadata": {
        "id": "CnNPOpyuSGv5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "visible1=Input(shape=(max_words,))\n",
        "model1=Embedding(max_features,100,mask_zero=True)(visible1)\n",
        "model1=LSTM(64,dropout=0.4, recurrent_dropout=0.4,return_sequences=True)(model1)\n",
        "model1=LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False)(model1)\n",
        "model1=Dense(64,activation='relu')(model1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nmqk0S-oVKVg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CNN Model"
      ]
    },
    {
      "metadata": {
        "id": "eCdAJiQeVJjJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "visible2=Input(shape=(max_words,))\n",
        "model2=Embedding(max_features,100,input_length=max_words)(visible2)\n",
        "model2=Dropout(0.2)(model2)\n",
        "model2=Conv1D(64,kernel_size=3,padding='same',activation='relu',strides=1)(model2)\n",
        "model2=GlobalMaxPooling1D()(model2)\n",
        "model2=Dense(128,activation='relu')(model2)\n",
        "model2=Dropout(0.2)(model2)\n",
        "model2=Dense(64,activation='relu')(model2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zzg8LzK8V0Vf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CNN+GRU Model"
      ]
    },
    {
      "metadata": {
        "id": "7FipPTLBVzxe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "visible3=Input(shape=(max_words,))\n",
        "model3=Embedding(max_features,100,input_length=max_words)(visible3)\n",
        "model3=Conv1D(64,kernel_size=3,padding='same',activation='relu')(model3)\n",
        "model3=MaxPooling1D(pool_size=2)(model3)\n",
        "model3=Dropout(0.25)(model3)\n",
        "model3=GRU(128,return_sequences=True)(model3)\n",
        "model3=Dropout(0.3)(model3)\n",
        "model3=Flatten()(model3)\n",
        "model3=Dense(128,activation='relu')(model3)\n",
        "model3=Dropout(0.5)(model3)\n",
        "model3=Dense(64,activation='relu')(model3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "muPAhpf_W8aF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Bidirectional GRU Model"
      ]
    },
    {
      "metadata": {
        "id": "4u2hvA5aXAXo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "visible4=Input(shape=(max_words,))\n",
        "model4=Embedding(max_features, 100, input_length=max_words)(visible4)\n",
        "model4=SpatialDropout1D(0.25)(model4)\n",
        "model4=Bidirectional(GRU(128))(model4)\n",
        "model4=Dropout(0.5)(model4)\n",
        "model4=Dense(64, activation='relu')(model4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7tMntLWSXWIR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Glove word embedding Model"
      ]
    },
    {
      "metadata": {
        "id": "tVF2FrGeXZ7W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_coefs(word, *arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "    \n",
        "def get_embed_mat(EMBEDDING_FILE, max_features,embed_dim):\n",
        "    # word vectors\n",
        "    embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding='utf8'))\n",
        "    print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "    # embedding matrix\n",
        "    word_index = tokenizer.word_index\n",
        "    num_words = min(max_features, len(word_index) + 1)\n",
        "    all_embs = np.stack(embeddings_index.values()) #for random init\n",
        "    embedding_matrix = np.random.normal(all_embs.mean(), all_embs.std(), \n",
        "                                        (num_words, embed_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features:\n",
        "            continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    max_features = embedding_matrix.shape[0]\n",
        "    \n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aL6fffbTXc2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0aead742-7103-44c3-fdd7-9aca568d6c4f"
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_FILE = 'glove.6B.100d.txt'\n",
        "embed_dim = 100 #word vector dim\n",
        "embedding_matrix = get_embed_mat(EMBEDDING_FILE,max_features,embed_dim)\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n",
            "(13717, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0MLhzWT5Xe-k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "visible5=Input(shape=(max_words,))\n",
        "model5=Embedding(max_features, embed_dim, input_length=X_train.shape[1],weights=[embedding_matrix],trainable=True)(visible5)\n",
        "model5=SpatialDropout1D(0.25)(model5)\n",
        "model5=Bidirectional(GRU(128,return_sequences=True))(model5)\n",
        "model5=Bidirectional(GRU(64,return_sequences=False))(model5)\n",
        "model5=Dropout(0.5)(model5)\n",
        "model5=Dense(64, activation='relu')(model5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RZtwja7jeQc-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Merge all models. Note in previous attempts, XGBoost in 2nd stage with imbalanced classes(without attempting undersampling or oversampling) was not working well. "
      ]
    },
    {
      "metadata": {
        "id": "BHdNO4qKeS8K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers.merge import concatenate\n",
        "\n",
        "model = concatenate([model1, model2, model3, model4, model5], axis=1)\n",
        "#model = concatenate([model, model3], axis=1)\n",
        "#model = concatenate([model, model4], axis=1)\n",
        "#model = concatenate([model, model5], axis=1)\n",
        "#model=np.array(model)\n",
        "#model = Conv1D(16,kernel_size=3,padding='same',activation='relu',strides=1)(model)\n",
        "#model = Conv1D(32,kernel_size=3,padding='same',activation='relu',strides=1)(model)\n",
        "#model = Conv1D(64,kernel_size=3,padding='same',activation='relu',strides=1)(model)\n",
        "#model=GlobalMaxPooling1D()(model)\n",
        "#model=Flatten()(model)\n",
        "model=Dense(128)(model)\n",
        "model=BatchNormalization()(model)\n",
        "model=Activation('relu')(model)\n",
        "model=Dropout(0.5)(model)\n",
        "model=Dense(64)(model)\n",
        "model=BatchNormalization()(model)\n",
        "model=Activation('relu')(model)\n",
        "model=Dropout(0.5)(model)\n",
        "output=Dense(5,activation='softmax')(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UIQA7KRMdwRh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1907
        },
        "outputId": "8a767a35-f760-4753-ce4b-fd0397e25f39"
      },
      "cell_type": "code",
      "source": [
        "model_concat = Model(inputs=[visible1, visible2, visible3, visible4, visible5], outputs=output)\n",
        "model_concat.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model_concat.summary()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 48)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 48, 100)      1371700     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 48, 64)       19264       embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 48)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 24, 64)       0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 48, 100)      1371700     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 24, 64)       0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            (None, 48)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 48, 100)      0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "gru_1 (GRU)                     (None, 24, 128)      74112       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 48)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 48, 100)      1371700     input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            (None, 48)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 48, 64)       19264       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 24, 128)      0           gru_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 48, 100)      1371700     input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_2 (SpatialDro (None, 48, 100)      0           embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 48, 100)      1371700     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 64)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 3072)         0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_1 (SpatialDro (None, 48, 100)      0           embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 48, 256)      175872      spatial_dropout1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 48, 64)       42240       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          8320        global_max_pooling1d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 128)          393344      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 256)          175872      spatial_dropout1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 128)          123264      bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 32)           12416       lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 128)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 256)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 128)          0           bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           2112        lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 64)           8256        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 64)           8256        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 64)           16448       dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 64)           8256        dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 320)          0           dense_1[0][0]                    \n",
            "                                                                 dense_3[0][0]                    \n",
            "                                                                 dense_5[0][0]                    \n",
            "                                                                 dense_6[0][0]                    \n",
            "                                                                 dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 128)          41088       concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128)          512         dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 128)          0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 128)          0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 64)           8256        dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64)           256         dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64)           0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 64)           0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 5)            325         dropout_11[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 7,996,233\n",
            "Trainable params: 7,995,849\n",
            "Non-trainable params: 384\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e5hCzEVTTeE0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "fb9f77f3-de6f-4d43-f31b-d7fd14e2a9ef"
      },
      "cell_type": "code",
      "source": [
        "history=model_concat.fit([X_train, X_train, X_train, X_train, X_train], y_train, validation_data=([X_val, X_val, X_val, X_val, X_val], y_val),epochs=5, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 109242 samples, validate on 46818 samples\n",
            "Epoch 1/5\n",
            "109242/109242 [==============================] - 847s 8ms/step - loss: 1.1758 - acc: 0.5361 - val_loss: 0.9096 - val_acc: 0.6248\n",
            "Epoch 2/5\n",
            "109242/109242 [==============================] - 847s 8ms/step - loss: 0.8570 - acc: 0.6504 - val_loss: 0.8173 - val_acc: 0.6529\n",
            "Epoch 3/5\n",
            "109242/109242 [==============================] - 844s 8ms/step - loss: 0.7681 - acc: 0.6832 - val_loss: 0.8146 - val_acc: 0.6562\n",
            "Epoch 4/5\n",
            "109242/109242 [==============================] - 846s 8ms/step - loss: 0.7025 - acc: 0.7074 - val_loss: 0.8361 - val_acc: 0.6590\n",
            "Epoch 5/5\n",
            "109242/109242 [==============================] - 843s 8ms/step - loss: 0.6484 - acc: 0.7285 - val_loss: 0.8534 - val_acc: 0.6539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Ytz_fSe_A0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cce5130b-25e9-44fc-f440-24c219eec0e6"
      },
      "cell_type": "code",
      "source": [
        "y_pred=model_concat.predict([X_test, X_test, X_test, X_test, X_test], verbose=1)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66292/66292 [==============================] - 708s 11ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MiLIkrHmoqR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "202e20c1-3215-46ea-d8df-fd24b1d327bf"
      },
      "cell_type": "code",
      "source": [
        "y_pred=np.argmax(y_pred, axis = 1)\n",
        "print(y_pred.shape)\n",
        "\n",
        "from collections import Counter\n",
        "c = Counter( y_pred )\n",
        "print( c.items() )"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(66292,)\n",
            "dict_items([(3, 15151), (2, 35726), (1, 11608), (0, 2152), (4, 1655)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GBJ3gLLZpKFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "690deaac-a2a2-4636-b725-df13b59748e7"
      },
      "cell_type": "code",
      "source": [
        "sub.Sentiment=y_pred\n",
        "sub.to_csv('sub_ensemble1.csv',index=False)\n",
        "sub.head()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>156061</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156062</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>156063</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>156064</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>156065</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  Sentiment\n",
              "0  156061    3        \n",
              "1  156062    3        \n",
              "2  156063    2        \n",
              "3  156064    3        \n",
              "4  156065    2        "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "94QyCqXAqxP9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9J2eIL9Hqxab",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}